{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender Classification with Perceptron using First Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the required libraries\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222 280\n",
      "['aaradhya', 'adah', 'adhira', 'alisha', 'amoli', 'anaisha', 'ananya', 'anika', 'anushka', 'asmee', 'avni', 'carina', 'chara', 'drishti', 'ela', 'eshika', 'geetika', 'gulika', 'hiya', 'hiral', 'ira', 'ishana', 'ishita', 'jeevika', 'kaia', 'kashvi', 'keya', 'kimaya', 'krisha', 'larisa', 'laasya', 'mahika', 'mayra', 'mehar', 'mirai', 'mishka', 'naitee', 'navya', 'nyra', 'nehrika', 'neysa', 'pavati', 'prisha', 'ryka', 'rebecca', 'saanvi', 'sahana', 'sai', 'saisha', 'saira', 'saloni', 'shanaya', 'shrishti', 'sneha', 'turvi', 'taahira', 'taara', 'tanvi', 'viti', 'zara', 'aagya', 'aaina', 'aas', 'akaljeet', 'amanroop', 'anika', 'birva', 'bisanpreet', 'charanpreet', 'dilreet', 'ekkam', 'faal', 'gurleen', 'gurmeet', 'heer', 'harleen', 'harveen', 'ikamroop', 'isha', 'ishmeet', 'katiya', 'mehr', 'nihaara', 'paakhi', 'parminder', 'simrat', 'sukhdeep', 'sukhleen', 'shirina', 'tavleen', 'ami', 'askini', 'anvi', 'bandhini', 'bansari', 'charmi', 'chavi', 'charul', 'drisna', 'dhara', 'dhruvi', 'jaisnavi', 'inika', 'vaidarbhi', 'ujas', 'urvashi', 'unnati', 'tejshri', 'tapti', 'sachi', 'sudakshima', 'sujal', 'saiyeisha', 'saurya', 'nandani', 'manayi', 'jagruti', 'jheel', 'jasodhara', 'revathy', 'reesha', 'priyanshi', 'preshti', 'preeksha', 'pragyawati', 'niradhara', 'vaani', 'vaidehi', 'yashi', 'yuvati', 'alekhya', 'amolika', 'aaghnya', 'bethina', 'brishti', 'cauvery', 'dayanita', 'elavarasi', 'garvita', 'kshyanika', 'lokini', 'lithiksha', 'mythri', 'mriganayani', 'naomi', 'odathi', 'oeshi', 'prushti', 'rajisha', 'rency', 'ramyadevi', 'rajshree', 'rethushana', 'rupeshwari', 'revanthi', 'rukumani', 'tritiya', 'tejshri', 'utalika', 'vrusti', 'aadarshini', 'aadhilakshmi', 'alaimagal', 'amrapali', 'bhaskari', 'bhuvaneshwari', 'brahmani', 'chandika', 'damayanti', 'devaki', 'dhanyalakshmi', 'eswari', 'ezhil rani', 'indhumathi', 'keshini', 'meenakshi', 'nithya', 'sri kalavathi', 'vadivukkarasi', 'velvizhi', 'aakriti', 'anuja', 'aradhana', 'aaruni', 'akshata', 'anupriya', 'anuradha', 'bhavani', 'bimla', 'chhaya', 'chitra', 'damini', 'dhanashri', 'divya', 'ekta', 'gargi', 'gayatri', 'gauri', 'hardika', 'jahnavi', 'kavita', 'kalpana', 'kinjal', 'lavanya', 'nikita', 'renuka', 'saraswati', 'shivani', 'tanuja', 'ujwala', 'abhilasha', 'achala', 'alka', 'aghanashini', 'ashalata', 'bhanuni', 'bhagyalakshmi', 'mandakini', 'madhumita', 'chandraprabha', 'chandrika', 'deepika', 'sukhmani', 'tredha', 'ekantika', 'ecchumati', 'methra', 'chitragandha', 'kiranmayi', 'kundanika', 'shubhada', 'iksha', 'indumukhi', 'jini', 'harinakshi', 'reneeka', 'vallari', 'yashmita', 'vajra', 'zena', 'anam', 'aasma', 'alfiya', 'adeeba', 'badr', 'breshna', 'daneen', 'eirna', 'erum', 'fatheha', 'fatima', 'farzeen', 'gulnar', 'gulnaz', 'heena', 'hayat', 'idris', 'iqra', 'kalima', 'kubra', 'kyra', 'mehar', 'madeeha', 'mahira', 'maisha', 'mishka', 'noor', 'nazia', 'quasar', 'qayanat', 'rabhya', 'sara', 'shaheen', 'sabiha', 'sahana', 'samaira', 'wafiya', 'zaida', 'zaha', 'zur']\n",
      "['aahva', 'aadiv', 'aahan', 'aarav', 'akanksh', 'alex', 'anant', 'atiksh', 'ayaan', 'bhuv', 'bhavin', 'brijesh', 'dasya', 'gian', 'hem', 'himanshu', 'hemant', 'hritik', 'hridhan', 'idhant', 'ishank', 'jash', 'jay', 'joseph', 'kabir', 'kahaan', 'kairav', 'kevin', 'laksh', 'luv', 'manan', 'mohammad', 'naksh', 'nimit', 'nirav', 'pahal', 'parv', 'pranay', 'rachit', 'raj', 'ranbir', 'ranveer', 'rishabh', 'raunak', 'reyansh', 'rishaan', 'rishit', 'rohan', 'rudra', 'rushil', 'sadhil', 'sarthak', 'taarush', 'taksh', 'ved', 'vihaan', 'vivaan', 'yash', 'yug', 'zuber', 'aneeldeep', 'amardeep', 'angad', 'bhagatveer', 'charanjeet', 'daler', 'deepinder', 'fatehbir', 'guneet', 'harbir', 'harbhajan', 'inderpal', 'karanveer', 'kuwarjeet', 'lavindeep', 'manandeep', 'maanas', 'navjot', 'paramjot', 'raunaq', 'raftaar', 'sikandar', 'sarabjit', 'surjan', 'tanvir', 'upinder', 'umed', 'wasimjit', 'yuvraj', 'yogender', 'aarsh', 'amish', 'batuk', 'bhavesh', 'bhavik', 'bhavin', 'chintan', 'chirayu', 'daiwik', 'daksh', 'darsh', 'deval', 'dhaval', 'dharmesh', 'falgun', 'girish', 'hemendra', 'harsh', 'herik', 'ishanyu', 'jainam', 'jigar', 'joshil', 'jignesh', 'parth', 'preetesh', 'pujesh', 'priyanshu', 'sunil', 'yug', 'aadrik', 'aarv', 'bhargava', 'charish', 'dignesh', 'geetham', 'geethik', 'govindaram', 'kalaparan', 'kshatragna', 'mullinti', 'nayanesh', 'nihant', 'prajith', 'reshvind', 'rajasekaran', 'thanvye', 'srivasthav', 'sridhara', 'vishu', 'vijayrathna', 'venkatesh', 'aadithyakethu', 'aadhirai', 'bala subramani', 'bhagyanandana', 'chithravarma', 'chitrasen', 'devayan', 'girinath', 'jayadeva', 'navamani', 'nakulesh', 'oshin', 'prasannatmane', 'parasmaijyotishe', 'sudharma', 'samarpana', 'sriharsha', 'vishveshwara', 'vijayrathna', 'venkatesh', 'abhinay', 'ajinkya', 'amey', 'bhushan', 'chinmay', 'gajanan', 'gandharv', 'harshal', 'harshavardhan', 'lavnik', 'mandar', 'mayur', 'pranay', 'prathamesh', 'pushkar', 'sankalp', 'sanket', 'shantanu', 'shashank', 'siddhesh', 'ayushya', 'arulappan', 'arindham', 'bal mukund', 'balaark', 'chellamuthu', 'cheranraj', 'chidakash', 'chellamani', 'daithyakulantaka', 'dhyutidhara', 'eeswar', 'elilvendan', 'ethiraj', 'murlimanohar', 'maandavik', 'mal marugan', 'tusya udarchis', 'tatvagyanaprada', 'vighnarajendra', 'adib', 'basir', 'chafik', 'diya al din', 'ehan', 'fadil', 'hussain', 'ijaz', 'jabeer', 'karim', 'liban', 'mastan', 'najeeb', 'owez', 'parvez', 'qadir', 'riyad', 'suhail', 'taabish', 'umraa']\n"
     ]
    }
   ],
   "source": [
    "# Read the dataset\n",
    "f = open(\"data/girls.txt\", \"r\")\n",
    "girls = []\n",
    "for girl in f:\n",
    "    girls.append(girl[:-1].lower())\n",
    "\n",
    "f = open(\"data/boys.txt\", \"r\")\n",
    "boys = []\n",
    "for boy in f:\n",
    "    boys.append(boy[:-1].lower())\n",
    "\n",
    "print(len(boys), len(girls))\n",
    "print(girls)\n",
    "print(boys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(703, 1)\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "# Convert each name to feature vector\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Considering all bigrams and bias term\n",
    "num_feats = 703    # 26^2 bigrams + 1 bias term = 703 features\n",
    "\n",
    "for girl in girls:\n",
    "  vec = np.zeros(num_feats)\n",
    "  vec[num_feats-1] = 1   # Initialize bias term as 1\n",
    "\n",
    "  # Consider all letters\n",
    "  for letter in girl:\n",
    "  # Skipping whitespace and extra characters\n",
    "    if (ord(letter) < 97 or ord(letter) > 122):\n",
    "      continue\n",
    "    vec[ord(letter) - 97] += 1\n",
    "\n",
    "  # Consider all bigrams\n",
    "  for i in range(len(girl)-1):\n",
    "    bigram = girl[i:i+2]\n",
    "    if (ord(bigram[0]) < 97 or ord(bigram[0]) > 122 or ord(bigram[0]) < 97 or ord(bigram[1]) > 122):\n",
    "      continue\n",
    "    vec[26 + (ord(bigram[0]) - 97)*26 + (ord(bigram[1]) - 97)] += 1\n",
    "\n",
    "  vec = vec.reshape(-1, 1)\n",
    "  X.append(vec)\n",
    "  y.append(-1)\n",
    "\n",
    "for boy in boys:\n",
    "  vec = np.zeros(num_feats)\n",
    "  vec[num_feats-1] = 1\n",
    "\n",
    "  # Consider all letters\n",
    "  for letter in boy:\n",
    "  # Skipping whitespace and extra characters\n",
    "    if (ord(letter) < 97 or ord(letter) > 122):\n",
    "      continue\n",
    "    vec[ord(letter) - 97] += 1\n",
    "  \n",
    "  # Consider all bigrams\n",
    "  for i in range(len(boy)-1):\n",
    "    bigram = boy[i:i+2]\n",
    "    if (ord(bigram[0]) < 97 or ord(bigram[0]) > 122 or ord(bigram[0]) < 97 or ord(bigram[1]) > 122):\n",
    "      continue\n",
    "    vec[26 + (ord(bigram[0]) - 97)*26 + (ord(bigram[1]) - 97)] += 1\n",
    "\n",
    "  vec = vec.reshape(-1, 1)\n",
    "  X.append(vec)\n",
    "  y.append(1)\n",
    "\n",
    "# Printing sample feature vector and label\n",
    "print(X[0].shape)\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 451\n",
      "Number of test examples: 51\n"
     ]
    }
   ],
   "source": [
    "# Split training and test data\n",
    "\n",
    "test_size = 0.1\n",
    "\n",
    "data = list(zip(X, y))\n",
    "random.shuffle(data)\n",
    "\n",
    "split_index = int(len(data) * (1 - test_size))\n",
    "train_data = data[:split_index]\n",
    "test_data = data[split_index:]\n",
    "\n",
    "X_train, y_train = zip(*train_data)\n",
    "X_test, y_test = zip(*test_data)\n",
    "\n",
    "X_train, X_test = np.array(X_train), np.array(X_test)\n",
    "y_train, y_test = np.array(y_train), np.array(y_test)\n",
    "\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "print(f'Number of training examples: {len(X_train)}')\n",
    "print(f'Number of test examples: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining weights for perceptron\n",
    "W = np.zeros((num_feats, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y, W):\n",
    "    m = X.shape[0]\n",
    "\n",
    "    num_iterations = 0\n",
    "\n",
    "    # Continue till labels are classified\n",
    "    while True:\n",
    "        miss = 0\n",
    "        for j in range(m):\n",
    "            Z = y[j]*(np.dot(W.T, X[j]))\n",
    "            if (Z[0][0] <= 0):\n",
    "                W = W + y[j]*X[j]\n",
    "                miss += 1\n",
    "        \n",
    "        if (num_iterations % 100 == 0):\n",
    "            print(f\"Iteration {num_iterations}: {miss} missclassifications\")\n",
    "            \n",
    "        num_iterations += 1\n",
    "\n",
    "        if (miss == 0):\n",
    "            print(f\"Iteration {num_iterations}: Converged!\")\n",
    "            break\n",
    "        \n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: 194 missclassifications\n",
      "Iteration 100: 29 missclassifications\n",
      "Iteration 200: 8 missclassifications\n",
      "Iteration 202: Converged!\n"
     ]
    }
   ],
   "source": [
    "W = fit(X_train, y_train, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test samples: 51\n",
      "Number of missclassified samples: 12\n",
      "Accuracy on test set: 0.7647058823529411\n"
     ]
    }
   ],
   "source": [
    "def get_accuracy(X, y, W):\n",
    "\n",
    "    m = X.shape[0]\n",
    "    print(f\"Total number of test samples: {m}\")\n",
    "\n",
    "    miss = 0\n",
    "    for j in range(m):\n",
    "        Z = y[j]*(np.dot(W.T, X[j]))\n",
    "        if (Z[0][0] <= 0):\n",
    "            miss += 1\n",
    "    \n",
    "    print(f\"Number of missclassified samples: {miss}\")\n",
    "\n",
    "    return (m-miss)/m\n",
    "\n",
    "accuracy = get_accuracy(X_test, y_test, W)\n",
    "print(f\"Accuracy on test set: {accuracy}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(name):\n",
    "    # Convert name to feature vector\n",
    "\n",
    "    name = name.lower()\n",
    "    \n",
    "    # Considering all bigrams and bias term\n",
    "    num_feats = 703    # 26^2 bigrams + 1 bias term = 677 features\n",
    "\n",
    "    vec = np.zeros(num_feats)\n",
    "    vec[num_feats-1] = 1   # Initialize bias term as 1\n",
    "\n",
    "    # Consider all letters\n",
    "    for letter in name:\n",
    "    # Skipping whitespace and extra characters\n",
    "        if (ord(letter) < 97 or ord(letter) > 122):\n",
    "            continue\n",
    "        vec[ord(letter) - 97] += 1\n",
    "\n",
    "    # Consider all bigrams\n",
    "    for i in range(len(name)-1):\n",
    "        bigram = name[i:i+2]\n",
    "        if (ord(bigram[0]) < 97 or ord(bigram[0]) > 122 or ord(bigram[0]) < 97 or ord(bigram[1]) > 122):\n",
    "            continue\n",
    "        vec[26 + (ord(bigram[0]) - 97)*26 + (ord(bigram[1]) - 97)] += 1\n",
    "\n",
    "    vec = vec.reshape(-1, 1)\n",
    "    \n",
    "    z = np.dot(W.T, vec)\n",
    "\n",
    "    if z > 0:\n",
    "        print(\"I am sure \" + name + \" is a boy.\")\n",
    "    elif z < 0:\n",
    "        print(\"I am sure \" + name + \" is a girl.\")\n",
    "    else:\n",
    "        print(\"I am not sure if \" + name + \" is a boy or a girl.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am sure chandan is a boy.\n",
      "I am sure chandanbala is a girl.\n"
     ]
    }
   ],
   "source": [
    "# Testing with our own example\n",
    "predict(\"Chandan\")\n",
    "predict(\"Chandanbala\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

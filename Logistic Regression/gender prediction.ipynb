{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender Classification with Logistic Regression using First Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "df = pd.read_csv(\"../assets/data/gender.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1296 entries, 0 to 1295\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Name    1296 non-null   object\n",
      " 1   Target  1296 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 20.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yash</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drashti</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Saloni</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Target\n",
       "0     Yash       1\n",
       "1     Prit       1\n",
       "2     Meet       1\n",
       "3  Drashti       0\n",
       "4   Saloni       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(702, 1)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Convert each name to feature vector\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Considering the last character and bigrams in name\n",
    "num_feats = 702    # 26 letters + 26*26 bigrams = 702 features\n",
    "\n",
    "for i in range(len(df)):\n",
    "  name = df.iloc[i]['Name']\n",
    "  target = df.iloc[i]['Target']\n",
    "\n",
    "  vec = np.zeros(num_feats)\n",
    "\n",
    "  # Consider last character\n",
    "  key = name[-1]\n",
    "  if (ord(key) < 97 or ord(key) > 122):\n",
    "    continue\n",
    "  vec[ord(key)-97] +=1\n",
    "\n",
    "  # Consider all bigrams\n",
    "  for i in range(len(name)-1):\n",
    "    bigram = name[i:i+2]\n",
    "    # Skipping whitespace and extra characters if any\n",
    "    if (ord(bigram[0]) < 97 or ord(bigram[0]) > 122 or ord(bigram[0]) < 97 or ord(bigram[1]) > 122):\n",
    "      continue\n",
    "    vec[26 + (ord(bigram[0]) - 97)*26 + (ord(bigram[1]) - 97)] += 1\n",
    "\n",
    "  vec = vec.reshape(-1, 1)\n",
    "  X.append(vec)\n",
    "\n",
    "  if target == 0:\n",
    "    # 0 represents girl\n",
    "    y.append(0)\n",
    "  else:\n",
    "    # 1 represents boy\n",
    "    y.append(1)\n",
    "\n",
    "# Printing sample feature vector and label\n",
    "print(X[0].shape)\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 1035\n",
      "Number of validation examples: 129\n",
      "Number of test examples: 130\n"
     ]
    }
   ],
   "source": [
    "# Split data into train, val and test sets\n",
    "test_size = 0.1\n",
    "val_size = 0.1\n",
    "\n",
    "data = list(zip(X, y))\n",
    "random.shuffle(data)\n",
    "\n",
    "split_index1 = int(len(data) * (1 - test_size - val_size))\n",
    "split_index2 = int(len(data) * (1 - test_size))\n",
    "train_data = data[:split_index1]\n",
    "val_data = data[split_index1:split_index2]\n",
    "test_data = data[split_index2:]\n",
    "\n",
    "X_train, y_train = zip(*train_data)\n",
    "X_test, y_test = zip(*test_data)\n",
    "X_val, y_val = zip(*val_data)\n",
    "\n",
    "X_train, X_test = np.array(X_train), np.array(X_test)\n",
    "y_train, y_test = np.array(y_train), np.array(y_test)\n",
    "X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "y_val = y_val.reshape(-1, 1)\n",
    "\n",
    "print(f'Number of training examples: {len(X_train)}')\n",
    "print(f'Number of validation examples: {len(X_val)}')\n",
    "print(f'Number of test examples: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the sigmoid function\n",
    "def sigmoid(z):\n",
    "    return (1.0 / (1 + np.exp(-z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes a forward pass\n",
    "def forward(X, W, b):\n",
    "    z = sigmoid(np.dot(X, W) + b)\n",
    "    return (z > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the binary cross-entropy loss\n",
    "def loss(y, y_hat):\n",
    "    epsilon = 1e-10\n",
    "    return -np.sum(y * np.log(y_hat + epsilon) + (1 - y) * np.log(1 - y_hat + epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains the logistic regression model using gradient descent\n",
    "def train(X, y, W, b, learning_rate=0.5, num_iterations=100000):\n",
    "    X = np.squeeze(X)\n",
    "    m = X.shape[0]\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        z = np.dot(X, W) + b\n",
    "        a = sigmoid(z)\n",
    "        if (i % 1000 == 0):\n",
    "            print(\"Loss at iteration\", i, \"is\", loss(y, a))\n",
    "        dz = a - y\n",
    "        dW = (1 / m) * np.dot(dz.T, X)\n",
    "        db = (1 / m) * np.sum(dz)\n",
    "        W = W - (learning_rate*(dW.T))\n",
    "        b = b - (learning_rate * db)\n",
    "    \n",
    "    return W, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the accuracy of the model\n",
    "def get_accuracy(X, y, W, b):\n",
    "    X = np.squeeze(X)\n",
    "    m = X.shape[0]\n",
    "    print(f\"Total number of samples: {m}\")\n",
    "\n",
    "    Z = forward(X, W, b)\n",
    "    equal_elements = np.sum(Z == y)\n",
    "    print(f\"Number of correct predictions: {equal_elements}\")\n",
    "    return equal_elements/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the confusion matrix for the model\n",
    "def confusion_matrix(X, y, W, b):\n",
    "    X = np.squeeze(X)\n",
    "    m = X.shape[0]\n",
    "\n",
    "    Z = forward(X, W, b)\n",
    "\n",
    "    cf = [[0, 0], [0, 0]]\n",
    "    \n",
    "    for i in range(len(Z)):\n",
    "        if Z[i] == 0 and y[i] == 0:\n",
    "            cf[0][0] += 1\n",
    "        elif Z[i] == 0 and y[i] == 1:\n",
    "            cf[0][1] += 1\n",
    "        elif Z[i] == 1 and y[i] == 0:\n",
    "            cf[1][0] += 1\n",
    "        elif Z[i] == 1 and y[i] == 1:\n",
    "            cf[1][1] += 1\n",
    "\n",
    "    return cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining weights and bias\n",
    "W = np.zeros((num_feats, 1))\n",
    "b = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at iteration 0 is 717.4073316725433\n",
      "Loss at iteration 1000 is 258.5933679186586\n",
      "Loss at iteration 2000 is 229.116389005167\n",
      "Loss at iteration 3000 is 213.13796425070836\n",
      "Loss at iteration 4000 is 202.4472696832884\n",
      "Loss at iteration 5000 is 194.5724858752591\n",
      "Loss at iteration 6000 is 188.43493831925002\n",
      "Loss at iteration 7000 is 183.46779353926917\n",
      "Loss at iteration 8000 is 179.33688881309138\n",
      "Loss at iteration 9000 is 175.82893593060663\n",
      "Total number of samples: 129\n",
      "Number of correct predictions: 118\n",
      "Accuracy on validation set: 0.9147286821705426\n"
     ]
    }
   ],
   "source": [
    "# Tuning hyperparameters using validation set\n",
    "W, b = train(X_train, y_train, W, b, 0.5, 10000)\n",
    "\n",
    "val_accuracy = get_accuracy(X_val, y_val, W, b)\n",
    "print(f\"Accuracy on validation set: {val_accuracy}\")\n",
    "\n",
    "# Reset parameters for changing hyperparameters and tuning again\n",
    "W = np.zeros((num_feats, 1))\n",
    "b = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at iteration 0 is 806.8233179389763\n",
      "Loss at iteration 1000 is 288.0327909929472\n",
      "Loss at iteration 2000 is 255.2542295556753\n",
      "Loss at iteration 3000 is 237.6714069557526\n",
      "Loss at iteration 4000 is 226.02842361307182\n",
      "Loss at iteration 5000 is 217.50340801530194\n",
      "Loss at iteration 6000 is 210.877239163816\n",
      "Loss at iteration 7000 is 205.5201105230677\n",
      "Loss at iteration 8000 is 201.06633458759146\n",
      "Loss at iteration 9000 is 197.28504311434168\n"
     ]
    }
   ],
   "source": [
    "# Training on both train and validation dataset\n",
    "X_train_val = np.concatenate((X_train, X_val))\n",
    "y_train_val = np.concatenate((y_train, y_val))\n",
    "W, b = train(X_train_val, y_train_val, W, b, 0.5, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 130\n",
      "Number of correct predictions: 111\n",
      "Accuracy on test set: 0.8538461538461538\n"
     ]
    }
   ],
   "source": [
    "accuracy = get_accuracy(X_test, y_test, W, b)\n",
    "print(f\"Accuracy on test set: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56, 7], [12, 55]]\n"
     ]
    }
   ],
   "source": [
    "cf = confusion_matrix(X_test, y_test, W, b)\n",
    "print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(name):\n",
    "    # Convert name to feature vector\n",
    "    name = name.lower()\n",
    "\n",
    "    vec = np.zeros(num_feats)\n",
    "\n",
    "    # Consider all letters\n",
    "    for letter in name:\n",
    "    # Skipping whitespace and extra characters\n",
    "        if (ord(letter) < 97 or ord(letter) > 122):\n",
    "            continue\n",
    "        vec[ord(letter) - 97] += 1\n",
    "\n",
    "    # Consider all bigrams\n",
    "    for i in range(len(name)-1):\n",
    "        bigram = name[i:i+2]\n",
    "        if (ord(bigram[0]) < 97 or ord(bigram[0]) > 122 or ord(bigram[0]) < 97 or ord(bigram[1]) > 122):\n",
    "            continue\n",
    "        vec[26 + (ord(bigram[0]) - 97)*26 + (ord(bigram[1]) - 97)] += 1\n",
    "\n",
    "    # vec = vec.reshape(-1, 1)\n",
    "\n",
    "    z = forward(vec, W, b)\n",
    "\n",
    "    if z == 1:\n",
    "        print(\"I am sure \" + name + \" is a boy.\")\n",
    "    elif z == 0:\n",
    "        print(\"I am sure \" + name + \" is a girl.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am sure preet is a boy.\n",
      "I am sure preeti is a girl.\n"
     ]
    }
   ],
   "source": [
    "# Testing with our own example\n",
    "predict(\"Preet\")\n",
    "predict(\"Preeti\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

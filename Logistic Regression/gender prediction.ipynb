{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender Classification with Logistic Regression using First Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "df = pd.read_csv(\"../assets/data/gender.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1294 entries, 0 to 1293\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Name    1294 non-null   object\n",
      " 1   Target  1294 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 20.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yash</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drashti</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Saloni</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Target\n",
       "0     Yash       1\n",
       "1     Prit       1\n",
       "2     Meet       1\n",
       "3  Drashti       0\n",
       "4   Saloni       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(702, 1)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Convert each name to feature vector\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Considering the last character and bigrams in name\n",
    "num_feats = 702    # 26 letters + 26*26 bigrams = 702 features\n",
    "\n",
    "for i in range(len(df)):\n",
    "  name = df.iloc[i]['Name']\n",
    "  target = df.iloc[i]['Target']\n",
    "\n",
    "  vec = np.zeros(num_feats)\n",
    "\n",
    "  # Consider last character\n",
    "  key = name[-1]\n",
    "  if (ord(key) < 97 or ord(key) > 122):\n",
    "    continue\n",
    "  vec[ord(key)-97] +=1\n",
    "\n",
    "  # Consider all bigrams\n",
    "  for i in range(len(name)-1):\n",
    "    bigram = name[i:i+2]\n",
    "    # Skipping whitespace and extra characters if any\n",
    "    if (ord(bigram[0]) < 97 or ord(bigram[0]) > 122 or ord(bigram[0]) < 97 or ord(bigram[1]) > 122):\n",
    "      continue\n",
    "    vec[26 + (ord(bigram[0]) - 97)*26 + (ord(bigram[1]) - 97)] += 1\n",
    "\n",
    "  vec = vec.reshape(-1, 1)\n",
    "  X.append(vec)\n",
    "\n",
    "  if target == 0:\n",
    "    # 0 represents girl\n",
    "    y.append(0)\n",
    "  else:\n",
    "    # 1 represents boy\n",
    "    y.append(1)\n",
    "\n",
    "# Printing sample feature vector and label\n",
    "print(X[0].shape)\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 1034\n",
      "Number of validation examples: 129\n",
      "Number of test examples: 130\n"
     ]
    }
   ],
   "source": [
    "# Split data into train, val and test sets\n",
    "test_size = 0.1\n",
    "val_size = 0.1\n",
    "\n",
    "data = list(zip(X, y))\n",
    "random.shuffle(data)\n",
    "\n",
    "split_index1 = int(len(data) * (1 - test_size - val_size))\n",
    "split_index2 = int(len(data) * (1 - test_size))\n",
    "train_data = data[:split_index1]\n",
    "val_data = data[split_index1:split_index2]\n",
    "test_data = data[split_index2:]\n",
    "\n",
    "X_train, y_train = zip(*train_data)\n",
    "X_test, y_test = zip(*test_data)\n",
    "X_val, y_val = zip(*val_data)\n",
    "\n",
    "X_train, X_test = np.array(X_train), np.array(X_test)\n",
    "y_train, y_test = np.array(y_train), np.array(y_test)\n",
    "X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "y_val = y_val.reshape(-1, 1)\n",
    "\n",
    "print(f'Number of training examples: {len(X_train)}')\n",
    "print(f'Number of validation examples: {len(X_val)}')\n",
    "print(f'Number of test examples: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the sigmoid function\n",
    "def sigmoid(z):\n",
    "    return (1.0 / (1 + np.exp(-z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes a forward pass\n",
    "def forward(X, W, b):\n",
    "    z = sigmoid(np.dot(X, W) + b)\n",
    "    return (z > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the binary cross-entropy loss\n",
    "def loss(y, y_hat):\n",
    "    epsilon = 1e-10\n",
    "    return -np.sum(y * np.log(y_hat + epsilon) + (1 - y) * np.log(1 - y_hat + epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains the logistic regression model using gradient descent\n",
    "def train(X, y, W, b, learning_rate=0.5, num_iterations=100000):\n",
    "    X = np.squeeze(X)\n",
    "    m = X.shape[0]\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        z = np.dot(X, W) + b\n",
    "        a = sigmoid(z)\n",
    "        if (i % 1000 == 0):\n",
    "            print(\"Loss at iteration\", i, \"is\", loss(y, a))\n",
    "        dz = a - y\n",
    "        dW = (1 / m) * np.dot(dz.T, X)\n",
    "        db = (1 / m) * np.sum(dz)\n",
    "        W = W - (learning_rate*(dW.T))\n",
    "        b = b - (learning_rate * db)\n",
    "    \n",
    "    return W, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the accuracy of the model\n",
    "def get_accuracy(X, y, W, b):\n",
    "    X = np.squeeze(X)\n",
    "    m = X.shape[0]\n",
    "    print(f\"Total number of samples: {m}\")\n",
    "\n",
    "    Z = forward(X, W, b)\n",
    "    equal_elements = np.sum(Z == y)\n",
    "    print(f\"Number of correct predictions: {equal_elements}\")\n",
    "    return equal_elements/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the confusion matrix for the model\n",
    "def confusion_matrix(X, y, W, b):\n",
    "    X = np.squeeze(X)\n",
    "    m = X.shape[0]\n",
    "\n",
    "    Z = forward(X, W, b)\n",
    "\n",
    "    cf = [[0, 0], [0, 0]]\n",
    "    \n",
    "    for i in range(len(Z)):\n",
    "        if Z[i] == 0 and y[i] == 0:\n",
    "            cf[0][0] += 1\n",
    "        elif Z[i] == 0 and y[i] == 1:\n",
    "            cf[0][1] += 1\n",
    "        elif Z[i] == 1 and y[i] == 0:\n",
    "            cf[1][0] += 1\n",
    "        elif Z[i] == 1 and y[i] == 1:\n",
    "            cf[1][1] += 1\n",
    "\n",
    "    return cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining weights and bias\n",
    "W = np.zeros((num_feats, 1))\n",
    "b = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at iteration 0 is 716.7141844921834\n",
      "Loss at iteration 1000 is 252.5539515508693\n",
      "Loss at iteration 2000 is 223.66495561976316\n",
      "Loss at iteration 3000 is 207.49383996283981\n",
      "Loss at iteration 4000 is 196.59522214845643\n",
      "Loss at iteration 5000 is 188.5651493500119\n",
      "Loss at iteration 6000 is 182.3166531713868\n",
      "Loss at iteration 7000 is 177.26899009266316\n",
      "Loss at iteration 8000 is 173.07780068865594\n",
      "Loss at iteration 9000 is 169.5236423318483\n",
      "Total number of samples: 129\n",
      "Number of correct predictions: 114\n",
      "Accuracy on validation set: 0.8837209302325582\n"
     ]
    }
   ],
   "source": [
    "# Tuning hyperparameters using validation set\n",
    "W, b = train(X_train, y_train, W, b, 0.5, 10000)\n",
    "\n",
    "val_accuracy = get_accuracy(X_val, y_val, W, b)\n",
    "print(f\"Accuracy on validation set: {val_accuracy}\")\n",
    "\n",
    "# Reset parameters for changing hyperparameters and tuning again\n",
    "W = np.zeros((num_feats, 1))\n",
    "b = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at iteration 0 is 806.1301707586163\n",
      "Loss at iteration 1000 is 294.75818064075855\n",
      "Loss at iteration 2000 is 263.13896023119\n",
      "Loss at iteration 3000 is 245.605368660098\n",
      "Loss at iteration 4000 is 233.8750426616628\n",
      "Loss at iteration 5000 is 225.28780537396977\n",
      "Loss at iteration 6000 is 218.6495700141993\n",
      "Loss at iteration 7000 is 213.32358223482157\n",
      "Loss at iteration 8000 is 208.93158130172122\n",
      "Loss at iteration 9000 is 205.23187352462594\n"
     ]
    }
   ],
   "source": [
    "# Training on both train and validation dataset\n",
    "X_train_val = np.concatenate((X_train, X_val))\n",
    "y_train_val = np.concatenate((y_train, y_val))\n",
    "W, b = train(X_train_val, y_train_val, W, b, 0.5, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 130\n",
      "Number of correct predictions: 113\n",
      "Accuracy on test set: 0.8692307692307693\n"
     ]
    }
   ],
   "source": [
    "accuracy = get_accuracy(X_test, y_test, W, b)\n",
    "print(f\"Accuracy on test set: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[63, 7], [10, 50]]\n"
     ]
    }
   ],
   "source": [
    "cf = confusion_matrix(X_test, y_test, W, b)\n",
    "print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(name):\n",
    "    # Convert name to feature vector\n",
    "    name = name.lower()\n",
    "\n",
    "    vec = np.zeros(num_feats)\n",
    "\n",
    "    # Consider all letters\n",
    "    for letter in name:\n",
    "    # Skipping whitespace and extra characters\n",
    "        if (ord(letter) < 97 or ord(letter) > 122):\n",
    "            continue\n",
    "        vec[ord(letter) - 97] += 1\n",
    "\n",
    "    # Consider all bigrams\n",
    "    for i in range(len(name)-1):\n",
    "        bigram = name[i:i+2]\n",
    "        if (ord(bigram[0]) < 97 or ord(bigram[0]) > 122 or ord(bigram[0]) < 97 or ord(bigram[1]) > 122):\n",
    "            continue\n",
    "        vec[26 + (ord(bigram[0]) - 97)*26 + (ord(bigram[1]) - 97)] += 1\n",
    "\n",
    "    # vec = vec.reshape(-1, 1)\n",
    "\n",
    "    z = forward(vec, W, b)\n",
    "\n",
    "    if z == 1:\n",
    "        print(\"I am sure \" + name + \" is a boy.\")\n",
    "    elif z == 0:\n",
    "        print(\"I am sure \" + name + \" is a girl.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am sure preet is a boy.\n",
      "I am sure preeti is a girl.\n"
     ]
    }
   ],
   "source": [
    "# Testing with our own example\n",
    "predict(\"Preet\")\n",
    "predict(\"Preeti\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

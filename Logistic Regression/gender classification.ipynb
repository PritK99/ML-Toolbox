{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender Classification with Logistic Regression using First Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the required libraries\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222 280\n",
      "['aaradhya', 'adah', 'adhira', 'alisha', 'amoli', 'anaisha', 'ananya', 'anika', 'anushka', 'asmee', 'avni', 'carina', 'chara', 'drishti', 'ela', 'eshika', 'geetika', 'gulika', 'hiya', 'hiral', 'ira', 'ishana', 'ishita', 'jeevika', 'kaia', 'kashvi', 'keya', 'kimaya', 'krisha', 'larisa', 'laasya', 'mahika', 'mayra', 'mehar', 'mirai', 'mishka', 'naitee', 'navya', 'nyra', 'nehrika', 'neysa', 'pavati', 'prisha', 'ryka', 'rebecca', 'saanvi', 'sahana', 'sai', 'saisha', 'saira', 'saloni', 'shanaya', 'shrishti', 'sneha', 'turvi', 'taahira', 'taara', 'tanvi', 'viti', 'zara', 'aagya', 'aaina', 'aas', 'akaljeet', 'amanroop', 'anika', 'birva', 'bisanpreet', 'charanpreet', 'dilreet', 'ekkam', 'faal', 'gurleen', 'gurmeet', 'heer', 'harleen', 'harveen', 'ikamroop', 'isha', 'ishmeet', 'katiya', 'mehr', 'nihaara', 'paakhi', 'parminder', 'simrat', 'sukhdeep', 'sukhleen', 'shirina', 'tavleen', 'ami', 'askini', 'anvi', 'bandhini', 'bansari', 'charmi', 'chavi', 'charul', 'drisna', 'dhara', 'dhruvi', 'jaisnavi', 'inika', 'vaidarbhi', 'ujas', 'urvashi', 'unnati', 'tejshri', 'tapti', 'sachi', 'sudakshima', 'sujal', 'saiyeisha', 'saurya', 'nandani', 'manayi', 'jagruti', 'jheel', 'jasodhara', 'revathy', 'reesha', 'priyanshi', 'preshti', 'preeksha', 'pragyawati', 'niradhara', 'vaani', 'vaidehi', 'yashi', 'yuvati', 'alekhya', 'amolika', 'aaghnya', 'bethina', 'brishti', 'cauvery', 'dayanita', 'elavarasi', 'garvita', 'kshyanika', 'lokini', 'lithiksha', 'mythri', 'mriganayani', 'naomi', 'odathi', 'oeshi', 'prushti', 'rajisha', 'rency', 'ramyadevi', 'rajshree', 'rethushana', 'rupeshwari', 'revanthi', 'rukumani', 'tritiya', 'tejshri', 'utalika', 'vrusti', 'aadarshini', 'aadhilakshmi', 'alaimagal', 'amrapali', 'bhaskari', 'bhuvaneshwari', 'brahmani', 'chandika', 'damayanti', 'devaki', 'dhanyalakshmi', 'eswari', 'ezhil rani', 'indhumathi', 'keshini', 'meenakshi', 'nithya', 'sri kalavathi', 'vadivukkarasi', 'velvizhi', 'aakriti', 'anuja', 'aradhana', 'aaruni', 'akshata', 'anupriya', 'anuradha', 'bhavani', 'bimla', 'chhaya', 'chitra', 'damini', 'dhanashri', 'divya', 'ekta', 'gargi', 'gayatri', 'gauri', 'hardika', 'jahnavi', 'kavita', 'kalpana', 'kinjal', 'lavanya', 'nikita', 'renuka', 'saraswati', 'shivani', 'tanuja', 'ujwala', 'abhilasha', 'achala', 'alka', 'aghanashini', 'ashalata', 'bhanuni', 'bhagyalakshmi', 'mandakini', 'madhumita', 'chandraprabha', 'chandrika', 'deepika', 'sukhmani', 'tredha', 'ekantika', 'ecchumati', 'methra', 'chitragandha', 'kiranmayi', 'kundanika', 'shubhada', 'iksha', 'indumukhi', 'jini', 'harinakshi', 'reneeka', 'vallari', 'yashmita', 'vajra', 'zena', 'anam', 'aasma', 'alfiya', 'adeeba', 'badr', 'breshna', 'daneen', 'eirna', 'erum', 'fatheha', 'fatima', 'farzeen', 'gulnar', 'gulnaz', 'heena', 'hayat', 'idris', 'iqra', 'kalima', 'kubra', 'kyra', 'mehar', 'madeeha', 'mahira', 'maisha', 'mishka', 'noor', 'nazia', 'quasar', 'qayanat', 'rabhya', 'sara', 'shaheen', 'sabiha', 'sahana', 'samaira', 'wafiya', 'zaida', 'zaha', 'zur']\n",
      "['aahva', 'aadiv', 'aahan', 'aarav', 'akanksh', 'alex', 'anant', 'atiksh', 'ayaan', 'bhuv', 'bhavin', 'brijesh', 'dasya', 'gian', 'hem', 'himanshu', 'hemant', 'hritik', 'hridhan', 'idhant', 'ishank', 'jash', 'jay', 'joseph', 'kabir', 'kahaan', 'kairav', 'kevin', 'laksh', 'luv', 'manan', 'mohammad', 'naksh', 'nimit', 'nirav', 'pahal', 'parv', 'pranay', 'rachit', 'raj', 'ranbir', 'ranveer', 'rishabh', 'raunak', 'reyansh', 'rishaan', 'rishit', 'rohan', 'rudra', 'rushil', 'sadhil', 'sarthak', 'taarush', 'taksh', 'ved', 'vihaan', 'vivaan', 'yash', 'yug', 'zuber', 'aneeldeep', 'amardeep', 'angad', 'bhagatveer', 'charanjeet', 'daler', 'deepinder', 'fatehbir', 'guneet', 'harbir', 'harbhajan', 'inderpal', 'karanveer', 'kuwarjeet', 'lavindeep', 'manandeep', 'maanas', 'navjot', 'paramjot', 'raunaq', 'raftaar', 'sikandar', 'sarabjit', 'surjan', 'tanvir', 'upinder', 'umed', 'wasimjit', 'yuvraj', 'yogender', 'aarsh', 'amish', 'batuk', 'bhavesh', 'bhavik', 'bhavin', 'chintan', 'chirayu', 'daiwik', 'daksh', 'darsh', 'deval', 'dhaval', 'dharmesh', 'falgun', 'girish', 'hemendra', 'harsh', 'herik', 'ishanyu', 'jainam', 'jigar', 'joshil', 'jignesh', 'parth', 'preetesh', 'pujesh', 'priyanshu', 'sunil', 'yug', 'aadrik', 'aarv', 'bhargava', 'charish', 'dignesh', 'geetham', 'geethik', 'govindaram', 'kalaparan', 'kshatragna', 'mullinti', 'nayanesh', 'nihant', 'prajith', 'reshvind', 'rajasekaran', 'thanvye', 'srivasthav', 'sridhara', 'vishu', 'vijayrathna', 'venkatesh', 'aadithyakethu', 'aadhirai', 'bala subramani', 'bhagyanandana', 'chithravarma', 'chitrasen', 'devayan', 'girinath', 'jayadeva', 'navamani', 'nakulesh', 'oshin', 'prasannatmane', 'parasmaijyotishe', 'sudharma', 'samarpana', 'sriharsha', 'vishveshwara', 'vijayrathna', 'venkatesh', 'abhinay', 'ajinkya', 'amey', 'bhushan', 'chinmay', 'gajanan', 'gandharv', 'harshal', 'harshavardhan', 'lavnik', 'mandar', 'mayur', 'pranay', 'prathamesh', 'pushkar', 'sankalp', 'sanket', 'shantanu', 'shashank', 'siddhesh', 'ayushya', 'arulappan', 'arindham', 'bal mukund', 'balaark', 'chellamuthu', 'cheranraj', 'chidakash', 'chellamani', 'daithyakulantaka', 'dhyutidhara', 'eeswar', 'elilvendan', 'ethiraj', 'murlimanohar', 'maandavik', 'mal marugan', 'tusya udarchis', 'tatvagyanaprada', 'vighnarajendra', 'adib', 'basir', 'chafik', 'diya al din', 'ehan', 'fadil', 'hussain', 'ijaz', 'jabeer', 'karim', 'liban', 'mastan', 'najeeb', 'owez', 'parvez', 'qadir', 'riyad', 'suhail', 'taabish', 'umraa']\n"
     ]
    }
   ],
   "source": [
    "# Read the dataset\n",
    "f = open(\"../assets/data/girls.txt\", \"r\")\n",
    "girls = []\n",
    "for girl in f:\n",
    "    girls.append(girl[:-1].lower())\n",
    "\n",
    "f = open(\"../assets/data/boys.txt\", \"r\")\n",
    "boys = []\n",
    "for boy in f:\n",
    "    boys.append(boy[:-1].lower())\n",
    "\n",
    "print(len(boys), len(girls))\n",
    "print(girls)\n",
    "print(boys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(702, 1)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Convert each name to feature vector\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Considering all bigrams and last character\n",
    "num_feats = 702    # 26 letters + 26*26 bigrams = 702 features\n",
    "\n",
    "for girl in girls:\n",
    "  vec = np.zeros(num_feats)\n",
    "\n",
    "  # Consider all letters\n",
    "  for letter in girl:\n",
    "    # Skipping whitespace and extra characters\n",
    "    if (ord(letter) < 97 or ord(letter) > 122):\n",
    "      continue\n",
    "    vec[ord(letter) - 97] += 1\n",
    "\n",
    "  # Consider all bigrams\n",
    "  for i in range(len(girl)-1):\n",
    "    bigram = girl[i:i+2]\n",
    "    if (ord(bigram[0]) < 97 or ord(bigram[0]) > 122 or ord(bigram[0]) < 97 or ord(bigram[1]) > 122):\n",
    "      continue\n",
    "    vec[26 + (ord(bigram[0]) - 97)*26 + (ord(bigram[1]) - 97)] += 1\n",
    "\n",
    "  vec = vec.reshape(-1, 1)\n",
    "  X.append(vec)\n",
    "  y.append(0)\n",
    "\n",
    "for boy in boys:\n",
    "  vec = np.zeros(num_feats)\n",
    "\n",
    "  # Consider all letters\n",
    "  for letter in boy:\n",
    "    # Skipping whitespace and extra characters\n",
    "    if (ord(letter) < 97 or ord(letter) > 122):\n",
    "      continue\n",
    "    vec[ord(letter) - 97] += 1\n",
    "  \n",
    "  # Consider all bigrams\n",
    "  for i in range(len(boy)-1):\n",
    "    bigram = boy[i:i+2]\n",
    "    if (ord(bigram[0]) < 97 or ord(bigram[0]) > 122 or ord(bigram[0]) < 97 or ord(bigram[1]) > 122):\n",
    "      continue\n",
    "    vec[26 + (ord(bigram[0]) - 97)*26 + (ord(bigram[1]) - 97)] += 1\n",
    "\n",
    "  vec = vec.reshape(-1, 1)\n",
    "  X.append(vec)\n",
    "  y.append(1)\n",
    "\n",
    "# Printing sample feature vector and label\n",
    "print(X[0].shape)\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 401\n",
      "Number of validation examples: 50\n",
      "Number of test examples: 51\n"
     ]
    }
   ],
   "source": [
    "# Split training, validation and testing data\n",
    "\n",
    "test_size = 0.1\n",
    "val_size = 0.1\n",
    "\n",
    "data = list(zip(X, y))\n",
    "random.shuffle(data)\n",
    "\n",
    "split_index1 = int(len(data) * (1 - test_size - val_size))\n",
    "split_index2 = int(len(data) * (1 - test_size))\n",
    "train_data = data[:split_index1]\n",
    "val_data = data[split_index1:split_index2]\n",
    "test_data = data[split_index2:]\n",
    "\n",
    "\n",
    "X_train, y_train = zip(*train_data)\n",
    "X_test, y_test = zip(*test_data)\n",
    "X_val, y_val = zip(*val_data)\n",
    "\n",
    "X_train, X_test = np.array(X_train), np.array(X_test)\n",
    "y_train, y_test = np.array(y_train), np.array(y_test)\n",
    "X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "y_val = y_val.reshape(-1, 1)\n",
    "\n",
    "print(f'Number of training examples: {len(X_train)}')\n",
    "print(f'Number of validation examples: {len(X_val)}')\n",
    "print(f'Number of test examples: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return (1.0 / (1 + np.exp(-z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X, W, b):\n",
    "    z = sigmoid(np.dot(X, W) + b)\n",
    "    return (z > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y, y_hat):\n",
    "    epsilon = 1e-10\n",
    "    return -np.sum(y * np.log(y_hat + epsilon) + (1 - y) * np.log(1 - y_hat + epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining weights and bias\n",
    "W = np.zeros((num_feats, 1))\n",
    "b = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, W, b, learning_rate=0.5, num_iterations=100000):\n",
    "    X = np.squeeze(X)\n",
    "    m = X.shape[0]\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        z = np.dot(X, W) + b\n",
    "        a = sigmoid(z)\n",
    "        if (i % 10000 == 0):\n",
    "            print(\"Loss at iteration\", i, \"is\", loss(y, a))\n",
    "        dz = a - y\n",
    "        dW = (1 / m) * np.dot(dz.T, X)\n",
    "        db = (1 / m) * np.sum(dz)\n",
    "        W = W - (learning_rate*(dW.T))\n",
    "        b = b - (learning_rate * db)\n",
    "    \n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at iteration 0 is 277.95201932433804\n",
      "Loss at iteration 10000 is 25.88342276697327\n",
      "Loss at iteration 20000 is 15.596852405467057\n",
      "Loss at iteration 30000 is 11.289980859870088\n",
      "Loss at iteration 40000 is 8.874396297559354\n",
      "Loss at iteration 50000 is 7.3184707459093\n",
      "Loss at iteration 60000 is 6.229763246596679\n",
      "Loss at iteration 70000 is 5.424320476077932\n",
      "Loss at iteration 80000 is 4.803932184057068\n",
      "Loss at iteration 90000 is 4.311225749066947\n"
     ]
    }
   ],
   "source": [
    "W, b = train(X_train, y_train, W, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning hyperparameters using validation set\n",
    "def validate(X, y, W, b):\n",
    "    X = np.squeeze(X)\n",
    "    m = X.shape[0]\n",
    "    print(f\"Total number of test samples: {m}\")\n",
    "\n",
    "    Z = forward(X, W, b)\n",
    "    equal_elements = np.sum(Z == y)\n",
    "    print(f\"Number of correct predictions: {equal_elements}\")\n",
    "    return equal_elements/m\n",
    "\n",
    "val_accuracy = validate(X_val, y_val, W, b)\n",
    "print(f\"Accuracy on test set: {val_accuracy}\")\n",
    "print(W)\n",
    "print(b)\n",
    "\n",
    "# We observed that a high learning rate (e.g., 10) can cause the loss to decrease rapidly. However, these rapidly learned weights tend to be large and may not be optimal for the problem. While a lower learning rate (e.g., 0.5) might lead to a slower decrease in loss during training, it allows the model to learn smaller, more feasible weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at iteration 0 is 90.56930572485507\n"
     ]
    }
   ],
   "source": [
    "# Train on remaining validation set\n",
    "W, b = train(X_val, y_val, W, b, 0.5, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test samples: 51\n",
      "Number of correct predictions: 43\n",
      "Accuracy on test set: 0.8431372549019608\n"
     ]
    }
   ],
   "source": [
    "def get_accuracy(X, y, W, b):\n",
    "    X = np.squeeze(X)\n",
    "    m = X.shape[0]\n",
    "    print(f\"Total number of test samples: {m}\")\n",
    "\n",
    "    Z = forward(X, W, b)\n",
    "    equal_elements = np.sum(Z == y)\n",
    "    print(f\"Number of correct predictions: {equal_elements}\")\n",
    "    return equal_elements/m\n",
    "\n",
    "accuracy = get_accuracy(X_test, y_test, W, b)\n",
    "print(f\"Accuracy on test set: {accuracy}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(name):\n",
    "    # Convert name to feature vector\n",
    "\n",
    "    name = name.lower()\n",
    "\n",
    "    vec = np.zeros(num_feats)\n",
    "\n",
    "    # Consider all letters\n",
    "    for letter in name:\n",
    "    # Skipping whitespace and extra characters\n",
    "        if (ord(letter) < 97 or ord(letter) > 122):\n",
    "            continue\n",
    "        vec[ord(letter) - 97] += 1\n",
    "\n",
    "    # Consider all bigrams\n",
    "    for i in range(len(name)-1):\n",
    "        bigram = name[i:i+2]\n",
    "        if (ord(bigram[0]) < 97 or ord(bigram[0]) > 122 or ord(bigram[0]) < 97 or ord(bigram[1]) > 122):\n",
    "            continue\n",
    "        vec[26 + (ord(bigram[0]) - 97)*26 + (ord(bigram[1]) - 97)] += 1\n",
    "\n",
    "    # vec = vec.reshape(-1, 1)\n",
    "\n",
    "    z = forward(vec, W, b)\n",
    "\n",
    "    if z == 1:\n",
    "        print(\"I am sure \" + name + \" is a boy.\")\n",
    "    elif z == 0:\n",
    "        print(\"I am sure \" + name + \" is a girl.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am sure chandanbala is a boy.\n",
      "I am sure dhruvi is a girl.\n"
     ]
    }
   ],
   "source": [
    "# Testing with our own example\n",
    "predict(\"chandanbala\")\n",
    "predict(\"dhruvi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

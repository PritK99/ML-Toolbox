{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pritp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing all the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "articles = pd.read_csv(\"../assets/data/articles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7600 entries, 0 to 7599\n",
      "Data columns (total 1 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   article  7600 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 59.5+ KB\n"
     ]
    }
   ],
   "source": [
    "articles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fears for T N pension after talks Unions repre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Race is On: Second Private Team Sets Launc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ky. Company Wins Grant to Study Peptides (AP) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prediction Unit Helps Forecast Wildfires (AP) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Calif. Aims to Limit Farm-Related Smog (AP) AP...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article\n",
       "0  Fears for T N pension after talks Unions repre...\n",
       "1  The Race is On: Second Private Team Sets Launc...\n",
       "2  Ky. Company Wins Grant to Study Peptides (AP) ...\n",
       "3  Prediction Unit Helps Forecast Wildfires (AP) ...\n",
       "4  Calif. Aims to Limit Farm-Related Smog (AP) AP..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing all the articles\n",
    "def preprocess(articles):\n",
    "    ps = PorterStemmer()\n",
    "    sentences = []\n",
    "\n",
    "    for article in articles:\n",
    "        # Converting the article to lowercase\n",
    "        article = article.lower()\n",
    "\n",
    "        # Removing punctuations\n",
    "        article = article.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "        # Tokenization\n",
    "        words = article.split()\n",
    "        \n",
    "        # Stemming\n",
    "        words = [ps.stem(word) for word in words]\n",
    "\n",
    "        sentences.append(words)\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = preprocess(list(articles[\"article\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulory size: 19224\n"
     ]
    }
   ],
   "source": [
    "# Creating a vocabulory\n",
    "vocab = set()\n",
    "\n",
    "for sentence in sentences:\n",
    "    for word in sentence:\n",
    "        vocab.add(word)\n",
    "\n",
    "vocab = list(vocab)\n",
    "print(f'Vocabulory size: {len(vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary to map key to indices\n",
    "key_to_idx = {}\n",
    "i = 0\n",
    "\n",
    "for i in range(len(vocab)):\n",
    "    key_to_idx[vocab[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing term frequency\n",
    "tf = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    vec = np.zeros(len(vocab))\n",
    "\n",
    "    for word in sentence:\n",
    "        idx = key_to_idx.get(word)\n",
    "        vec[idx] += 1\n",
    "    \n",
    "    tf.append(vec)\n",
    "\n",
    "# Converting to numpy array\n",
    "tf = np.array(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/19224 words complete\n",
      "4000/19224 words complete\n",
      "6000/19224 words complete\n",
      "8000/19224 words complete\n",
      "10000/19224 words complete\n",
      "12000/19224 words complete\n",
      "14000/19224 words complete\n",
      "16000/19224 words complete\n",
      "18000/19224 words complete\n"
     ]
    }
   ],
   "source": [
    "# Storing inverse document frequency\n",
    "document_word_count = []\n",
    "\n",
    "iter = 0\n",
    "for curr_word in vocab:\n",
    "    count = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            if (curr_word == word):\n",
    "                count += 1\n",
    "                continue\n",
    "    \n",
    "    document_word_count.append(count)\n",
    "\n",
    "    iter += 1\n",
    "    if (iter % 2000 == 0):\n",
    "        print(f'{iter}/{len(vocab)} words complete')\n",
    "\n",
    "document_word_count = np.array(document_word_count)\n",
    "idf = np.log((1+len(sentences))/document_word_count)\n",
    "\n",
    "# This cell might require 5-10 minutes to run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating tf-idf representation for each article\n",
    "tf_idf = []\n",
    "for entry in tf:\n",
    "    tf_idf.append(entry*idf)\n",
    "\n",
    "tf_idf = np.array(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the K nearest neighbors based on dot product\n",
    "def get_nearest_neighbor(test, tf_idf, k=5):\n",
    "    recommendations = []\n",
    "\n",
    "    distance = np.dot(test, tf_idf.T)\n",
    "    top_indices = np.argsort(distance)[len(distance)-k:]\n",
    "\n",
    "    for idx in top_indices:\n",
    "        recommendations.append(articles.iloc[idx][0])\n",
    "    \n",
    "    recommendations = recommendations[::-1]\n",
    "\n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You might also like:\n",
      "Recommendation 1: E-mail scam targets police chief Wiltshire Police warns about \"phishing\" after its fraud squad chief was targeted.\n",
      "Recommendation 2: Tech Firms, FBI to Fight 'Phishing' Scams Together (Reuters) Reuters - Internet companies and\\law-enforcement agencies said on Wednesday they will work\\together to track down online scam artists who pose as banks\\and other legitimate businesses, a practice known as\\\"phishing.\"\n",
      "Recommendation 3: Sister of man who died in Vancouver police custody slams chief (Canadian Press) Canadian Press - VANCOUVER (CP) - The sister of a man who died after a violent confrontation with police has demanded the city's chief constable resign for defending the officer involved.\n",
      "Recommendation 4: Ex-U.S. Cyber Security Chief Sees Curb on Phishing &lt;p&gt;\\&lt;/p&gt;&lt;p&gt; By Lisa Baertlein&lt;/p&gt;&lt;p&gt; SAN FRANCISCO (Reuters) - A former White House Web security\\chief predicted on Wednesday that technology companies and law\\enforcers could soon stamp out most Internet \"phishing\" scams\\that aim to trick people into giving away personal and\\financial information.&lt;/p&gt;\n",
      "Recommendation 5: Blast Targets Baghdad Checkpoint Near Allawi HQ (Reuters) Reuters - A car bomb that exploded near the\\headquarters of Iraqi Prime Minister Iyad Allawi's party in\\western Baghdad on Monday targeted a police checkpoint at the\\entrance to the road leading to the building, witnesses said.\n"
     ]
    }
   ],
   "source": [
    "recommendations = get_nearest_neighbor(tf_idf[8], tf_idf)\n",
    "\n",
    "print(f'You might also like:')\n",
    "for i in range(len(recommendations)):\n",
    "    print(f'Recommendation {i+1}: {recommendations[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You might also like:\n",
      "Recommendation 1: Dollar Rises on the Interest Rate Plays  NEW YORK (Reuters) - The dollar rose on Thursday as  traders, short of dollars after relentlessly selling them for  weeks, looked to the growing yield advantage of U.S. assets as  a reason to buy back the currency before the end of the year.\n",
      "Recommendation 2: Dollar's Gains Cut as Fed Raises Rates  NEW YORK (Reuters) - The dollar's gains were clipped  on  Tuesday as the Federal Reserve raised interest rates for the  fifth time this year, as expected, but quashed hopes for more  aggressive rate tightening.\n"
     ]
    }
   ],
   "source": [
    "# Testing with our own data\n",
    "sample_article = \"The dollar slipped broadly on Friday as traders booked profits after recent gains but the U.S. currency remained well-placed for further advances, supported by strong U.S. economic data that has prompted markets to dial back expectations for interest rate cuts.\"\n",
    "\n",
    "# We need to provide sample article inside a list because of the way preprocess function is defined\n",
    "test_sentences = preprocess([sample_article])[0]\n",
    "test_tf = np.zeros(len(vocab))\n",
    "\n",
    "for word in test_sentences:\n",
    "    if word in vocab:\n",
    "        idx = key_to_idx.get(word)\n",
    "        test_tf[idx] += 1\n",
    "\n",
    "test_tf_idf = test_tf*idf\n",
    "\n",
    "recommendations = get_nearest_neighbor(test_tf_idf, tf_idf, 2)\n",
    "\n",
    "print(f'You might also like:')\n",
    "for i in range(len(recommendations)):\n",
    "    print(f'Recommendation {i+1}: {recommendations[i]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
